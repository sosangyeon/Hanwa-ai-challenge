custom dataset/dataloader
점점 많은 양의 data를 이용해서 딥러닝 모델을 학습시키는 일이 많아지면서 그 많은 양의 data를 한번에 불러오려면 시간이 오래걸리는 것을 넘어서서 RAM이 터지는 일이 발생한다. 
데이터를 한번에 다 부르지 않고 하나씩만 불러서 쓰는 방식을 택하면 메모리가 터지지 않고 모델을 돌릴 수 없다. 그래서 모든 데이터를 한번에 불러놓고 쓰는 기존의 dataset말고 
custom dataset을 만들어야할 필요가 있다. 또한 길이가 변하는 input에 대해서 batch를 만들땐 batch 묶는 방식을 우리가 정해주어야할 때 dataloader에서 batch를 만드는 부분을 수정해야할 필요가 있어 
custom dataloader를 사용한다. 

dataset
dataset class는 전체 dataset을 구성하는 단계이다. 
input으로는 전체 x(inpuet feature)와 y(label)을 tensor로 넣어주면 된다. dataset의 구성은 아래와 같다. 
__init__(self) : 여기서 필요한 변수들을 선언한다. 전체 x_data와 y_data load하거나 파일목록을 load한다.
__getitem__(self, index) : index번째 data를 return하도록 코드를 짜야한다. 
__len__(self) : x_data나 y_data는 길이가 같으므로 둘 중 하나의 length를 return하면 된다. 

Custom Dataset for big dataset
너무 큰 데이터셋이어서 RAM에 다 올릴 수 없을 때, 사용자정의 데이터셋을 정의해서 사용할 수 있다. 

1) __init__(self):
opt_data라는 매개변수를 통해 train인지 validation인지 선택할 수 있게 한다.
x_data가 대규모 데이터라고 하면 데이터를 다 불러오는데 시간과 메모리가 너무 많이 들 수 있다. 
그래서 x_data는 file name만 load해놓는 방식으로 구현하는 경우가 있다. 
file name은 txt나 json형식을 많이 사용한다. y_data의 경우 csv파일이기 때문에 한번에 불러서 y라는 변수에 저장한다. 
그리고 멤버함수에서 사용해야 하는 변수들은 self.을 이용해서 멤버변수로 설정해야 다른 함수에서 불러 사용할 수 있다. 
(멤버 함수(Member Function)는 클래스 내에서 정의된 함수, 이 함수는 클래스의 멤버 변수(Member Variable) 또는 속성(Attributes)에 접근하고 이를 조작할 수 있다.)

2) __gettiem__(self,index):
여기서는 전체 x_data와 y_data 중에 해당 index번째의 샘플을 뽑아오는 단계이다.
x_data의 경우 file_list에서 해당 index의 파일명을 불러와 이를 이용해서 index에 해당하는 샘플을 불러오면 된다. 
이후 x와 y[index]를 tensor로 변환해주기 위해 from_numpy함수를 사용했다. 모델에서 weight들이 float형태이기 때문에 .float()을 이용해서 float형으로 변환해주어야 한다. 

3) __len__(self):
여기서 전체 dataset의 size를 return하면 되기 때문에 x나 y의 length 중 아무거나 return하면 된다. testset의 경우는 y값이 없기 때문에 x length를 return하는 것이 공용으로 dataset을 정의하기에는 더 좋다. 

Dataloader
Dataloader class는 batch기반의 딥러닝모델 학습을 위해서 mini batch를 만들어주는 역할을 한다. 
dataloader를 통해 dataset의 전체 데이터가 batch size로 slice된다. 앞서 만들었던 dataset을 input으로 넣어주면 여러 옵션(데이터 묶기, 섞기, 알아서 병렬처리)을 통해 batch를 만들어준다.
서버에서 돌릴 때는 cpu num_worker를 조절해서 load속도를 올릴 수 있지만, PC에서는 default로 설정해야 오류가 안난다.
[Dataaloader의 주요 파라미터]
shuffle : (default:False) Train 일때는 True, 아닐때는 False
drop_last : (default : False) True시 맨 마지막에 나눠떨어지지 않는 batch를 버린다. (비효율적연산이 될 수 있기 때문) 
num_workers : (default : 0) cpu를 몇개 사용할지
collate_fn : batch를 만들어주는 함수

Custom Dataloader for variable length sequence
길이가 변하는 input을 처리하기 위해서 dataloader의 collate_fn을 사용자정의 함수로 다시 재정의하여 사용할 수 있다. 
(기본적으로, collate_fn은 주어진 샘플들을 그대로 묶어서 배치로 만듭니다. 하지만 입력 시퀀스의 길이가 다를 경우, 기본 동작은 제대로 작동하지 않을 수 있다. 
이를 해결하기 위해 collate_fn을 사용자 정의하여 시퀀스 길이에 따라 패딩(padding)을 추가하거나, 샘플을 다른 방식으로 정렬하는 등의 작업을 수행할 수 있다.)
길이가 다른 input을 batch로 만들기 위해 배치를 만들어주는 collate_fn을 조작할 필요가 있다. 





