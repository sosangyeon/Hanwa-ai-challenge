Abstract
이미지 융합, 보행자 감지 및 이미지과 같은 다양한 시각적 작업은 효과적인 대상 영역의 손실로 인해 저조도 조건에서 매우 어렵다. 
적외선 및 가시관선 이미지를 함께 사용하여 풍부한 세부 정보와 효과적인 대상 영역을 모두 제공할 수 있다.
이 경우 적외선 및 가시관선 이미지를 함께 사용하여 풍부한 세부 정봉와 효과적인 대상 영역을 모두 제공할 수 있다.
데이터 세트를 다른 가시광선 데이터 세트와 비교하고 데이터 세트에서 이미지 융합, 보행자 감지 및 이미지-이미지 변환을 포함한 일부 인기 있는 시각적 알고리즘을 평가한다.

1. Introduction
예를 들어, 효과적인 대상 영역의 손실로 인해 저조도 조건에서 제한된 품질의 가시 이미지에 대한 다양한 시각적 작업을 수행하는 것은 매우 어렵다. 
적외선 이미지는 물체 표면의 온도 필드를 통해 이미지화되므로 보행자와 같은 대상을 강조할 수 있지만 질감 정보가 누락된다. 
가시관선 및 적외선 이미지 융합은 풍부한 세부 정보와 효과적인 대상 영역을 모두 갖춘 단일 이미지를 생성할 수 있다. 
그런 다음 융합된 이미지를 인간의 시각적 인식, 물체 감지 및 비디오 감시에 적용할 수 있다.
이미지 융합의 목표는 소스 이미지에서 두드러진 특징을 추출하고 적절한 융합 방법을 통해 단일 이미지로 통합하는 것이다. 
이미지 융합 작업은 다양한 방법으로 개발되어 왔다. 딥러닝 알고리즘은 이미지 융합 분야에서 큰 성공을 거두었다.
데이터는 정확한 딥러닝 시스템을 구축하는데 필수적인 부분이므로 가시광선 및 적외선 쌍을 이루는 데이터 세트가 필요하다. 

우리는 저조도 시력을 위한 가시광선-적외선 쌍 데이터 세트인 LLVIP를 구축한다. 우리는 가시광선 카메라와 적외선 카메라로 구성된 쌍안경 카메라로 이미지를 수집한다. 
이러한 쌍안경 카메라는 시간과 공간에서 이미지 쌍의 일관성을 보장할 수 있다. 
각 이미지 쌍은 동일한 시야와 크기를 갖도록 등록되고 잘린다. 
이미지는 시간과 공간에서 엄격하게 정렬되므로 데이터 세트는 이미지 융합 및 이미지-이미지 변환에서 유용하다. 
LLVIP 데이터 세트에서 다양한 융합 알고리즘을 평가하고 결과를 주관적이고 객관적으로 분석한다.
fusion 알고리즘은 저조도에서 가시관선 이미지의 세부 사항을 캡처할 수 없다. 
또한 데이터 세트에서 일반적인 이미지-이미지 변환 알고리즘을 평가하는데 성능이 매우 떨어진다. 데이터 세트에는 저조도 조건에서 다양한 보행자가 많이 포함되어 있어 저조도 보행자 감지에 유용하다. 
1) 다양한 저조도 시각 작업을 위한 최초의 가시광선-적외선 상 데이터 세트인 LLVIP를 제안한다.
2) 정렬된 적외선 영상으로 저조도 가시광선 영상을 라벨링하고, LLVIP에서 보행자를 라벨링하는 방법을 제안한다.
3) LLVIP에서 이미지 융합, 보행자 감지 및 이미지-이미지 변환의 실험 결과를 평가한 결과, 데이터 세트가 모든 작업에서 큰 도전 과제임을 발견했다.

3. The LLVIP Dataset
우리가 사용하는 카메라 장비는 가시광선 카메라와 적외선 카메라로 구성된 쌍안경 카메라 플랫폼이다. 
열적외선 카메라의 작동 파장은 8~14um이다. 

가시광선 이미지와 적외선 이미지는 쌍안 카메라로 촬영되지만, 서로 다른 센서 카메라의 필드 크기가 다르기 때문에 정렬되지 않는다.
우리는 가시광선-적외선 이미지 쌍을 클리핑하고 등록하여 정확히 동일한 시야와 동일한 이미지 크기를 갖도록 했다. 

4.1. Image Fusion and Metric
이미지 융합은 소스 이미지에서 두드러진 특징을 추출하려고 시도한 다음 이러한 특징을 적절한 융합 방법에 의해 단일 이미지로 통합한다. 

4.1.1 Fusion methods
최근에는 많은 융합 방법이 제안되고 있다. 
FusionGAN 생성기는 융합 이미지에 적외선 이미지의 픽셀 강도와 가시 이미지의 기울기 정보를 포함하도록 한다. 
특징을 추출한 후 융합되 이미지와 가시광선 이미지를 구별하도록 설계되어 융합된 이미지가 가시광선 이미지의 더 많은 텍스처 정보를 포함할 수 있다. 

4.1.2 Fusion metrics
많은 융합 메트릭이 제안되고 있지만, 어느 것이 더 나은지 말하기 어렵기 때문에 융합 방법을 평가하기 위해 여러 메트릭을 선택할 필요가 있다. 
entropy, mutual information series, strutual similarity, Qabf 및 visual information fidelity for fusio을 사용하여 다양한 융합 방법의 성능을 객관적으로 평가한다.

EN: 정보 이론을 기반으로 정의되며, 퓨전된 이미지가 포함하는 정보의 양을 측정
MI (Mutual Information): 이미지 퓨전의 가장 일반적으로 사용되는 객관적 지표
Fusion Factor (FF): MI를 기반으로 한 개념
QMI (Normalized Mutual Information): 엔트로피와 상호 정보량을 기반으로 정의된 지표
SSIM (Structural Similarity Index): 데이터 압축이나 전송 과정에서 발생하는 이미지 품질 저하를 정량화하는 지각적 메트릭
Qabf: 입력 이미지들에 포함된 중요한 정보가 왜곡 없이 퓨전된 이미지로 얼마나 잘 전달되었는지를 나타내는 품질 지수
VIFF (Visual Information Fidelity in Fusion): VIF 모델을 활용하여 두 소스 이미지 쌍에서 시각적 정보를 포착하는 지표

4.2 Low-light Pedestrian Detection
보행자 감지는 자동 드라이브, 비디오 감시 및 인원 계산의 여러 응용 프로그램으로 인해 지난 몇 년동안 큰 진전을 이루었다.
보행자 감지 방법의 성능은 열악한 조명 조건에서 제한적으로 유지되며 저조도 조건에 대한 방법과 데이터 세트는 거의 없다.
yolo시리즈는 물체 감지에 가장 일반적으로 사용되는 1단계 알고리즘이다. 
컴퓨터 비전 기술이 발전함에 따라 이 시리즈는 계속해서 새로운 기술과 업데이트를 통합하고 있다. 
yolo 시리즈는 실험 결과는 기존 보행자 감지 알고리즘이 저조도 조건에서 잘 작동하지 않음을 보여준다.

4.3. Image-to-Image Translation
이미지 변환은 이미지를 한 도메인에서 다른 도메인으로 변환하는 기술입니다. 
cGAN의 개발로 큰 진전을 이루었다. 
가시광선 이미지와 비교했을 때, 적외선 이미지는 고가의 시설과 엄격한 촬영 조건으로 인해 캡처가 어렵다. 
이러한 제한을 극복하기 위해 이미지-이미지 변환 방법을 사용하여 쉽게 얻을 수 있는 가시광선 이미지로부터 적외선 데이터를 구성한다.
기존의 가시광선-적외선 변환 방법은 크게 두 가지 범주로 나눌 수 있는데, 하나는 물리적 모델 및 수동 이미지 변환 관계 설계의 사용이고, 다른 하나는 딥러닝 방법이다. 

